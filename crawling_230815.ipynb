{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf3d31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\hyunbin\\anaconda3\\lib\\site-packages (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hyunbin\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hyunbin\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hyunbin\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hyunbin\\anaconda3\\lib\\site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3d7880-1f1f-44cf-b0d2-931ed20c659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 가져오기\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1be97cf-2b87-4a85-94b4-c2d701cedf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image를 저장할 내 PC 경로 지정\n",
    "# /~/images/ 내에 top/man/, top/woman/ 디렉토리 필요\n",
    "my_Url = 'C:/Users/HYUNBIN/Desktop/공부/공개sw 공모전/source/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebf9383-cf8e-4015-aaee-5173cb58b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무신사 상의 1 page url 지정\n",
    "top_front_Url = 'https://www.musinsa.com/categories/item/001?d_cat_cd=001&brand=&list_kind=small&sort=pop_category&sub_sort=&page='\n",
    "top_end_Url = '&display_cnt=90&group_sale=&exclusive_yn=&sale_goods=&timesale_yn=&ex_soldout=&plusDeliveryYn=&kids=&color=&price1=&price2=&shoeSizeOption=&tags=&campaign_id=&includeKeywords=&measure='\n",
    "top_url_1 = top_front_Url + '1' + top_end_Url\n",
    "# 각 object 로드\n",
    "html = urlopen(top_url_1)\n",
    "soup = bs(html, \"html.parser\")\n",
    "li_box = soup.find_all(name='li', attrs={'class':'li_box'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83e1c43-435a-45cc-8dad-f3a64102d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "m=0\n",
    "print('start!')\n",
    "for i in li_box:\n",
    "    man = 0\n",
    "    woman = 0\n",
    "    try:\n",
    "        man = i.find(name='li', attrs={'class':'icon_man sight_out'})\n",
    "        man.get_text()\n",
    "        man = 1\n",
    "    except:\n",
    "        man = 0\n",
    "    try:\n",
    "        woman = i.find(name='li', attrs={'class':'icon_woman sight_out'})\n",
    "        woman.get_text()\n",
    "        woman = 1\n",
    "    except:\n",
    "        woman = 0\n",
    "    try:\n",
    "        img = i.find(name='img', attrs={'class':'lazyload lazy'})\n",
    "        img.attrs['data-original']\n",
    "        tmp_url = img.attrs['data-original']\n",
    "        if man == 1:\n",
    "            try:\n",
    "                with urlopen(tmp_url) as f:\n",
    "                    with open(my_Url + '/top/man/img' + str(n) + '.jpg', 'wb') as h:\n",
    "                        img = f.read()\n",
    "                        h.write(img)\n",
    "                        n+=1\n",
    "            except:\n",
    "                continue\n",
    "        if woman == 1:\n",
    "            try:\n",
    "                with urlopen(tmp_url) as f:\n",
    "                    with open(my_Url + '/top/woman/img' + str(m) + '.jpg', 'wb') as h:\n",
    "                        img = f.read()\n",
    "                        h.write(img)\n",
    "                        m+=1\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        continue\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb18674-b1ac-4f2d-a8de-93fc1a3b7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무신사 상의 2 page url 지정\n",
    "top_url_2 = top_front_Url + '2' + top_end_Url\n",
    "# 각 object 로드\n",
    "html = urlopen(top_url_2)\n",
    "soup = bs(html, \"html.parser\")\n",
    "li_box = soup.find_all(name='li', attrs={'class':'li_box'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d05fd3-d8d2-467e-9fea-e856c73cf6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('start!')\n",
    "for i in li_box:\n",
    "    man = 0\n",
    "    woman = 0\n",
    "    try:\n",
    "        man = i.find(name='li', attrs={'class':'icon_man sight_out'})\n",
    "        man.get_text()\n",
    "        man = 1\n",
    "    except:\n",
    "        man = 0\n",
    "    try:\n",
    "        woman = i.find(name='li', attrs={'class':'icon_woman sight_out'})\n",
    "        woman.get_text()\n",
    "        woman = 1\n",
    "    except:\n",
    "        woman = 0\n",
    "    try:\n",
    "        img = i.find(name='img', attrs={'class':'lazyload lazy'})\n",
    "        img.attrs['data-original']\n",
    "        tmp_url = img.attrs['data-original']\n",
    "        if man == 1:\n",
    "            try:\n",
    "                with urlopen(tmp_url) as f:\n",
    "                    with open(my_Url + '/top/man/img' + str(n) + '.jpg', 'wb') as h:\n",
    "                        img = f.read()\n",
    "                        h.write(img)\n",
    "                        n+=1\n",
    "            except:\n",
    "                continue\n",
    "        if woman == 1:\n",
    "            try:\n",
    "                with urlopen(tmp_url) as f:\n",
    "                    with open(my_Url + '/top/woman/img' + str(m) + '.jpg', 'wb') as h:\n",
    "                        img = f.read()\n",
    "                        h.write(img)\n",
    "                        m+=1\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        continue\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d16293-84c8-490c-9b9e-88da97e90021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무신사 상의 3 page url 지정\n",
    "top_url_3 = top_front_Url + '3' + top_end_Url\n",
    "# 각 object 로드\n",
    "html = urlopen(top_url_3)\n",
    "soup = bs(html, \"html.parser\")\n",
    "li_box = soup.find_all(name='li', attrs={'class':'li_box'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d12f5e5-c41f-43f7-97fa-cf2fdc0eb095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('start!')\n",
    "for i in li_box:\n",
    "    man = 0\n",
    "    woman = 0\n",
    "    try:\n",
    "        man = i.find(name='li', attrs={'class':'icon_man sight_out'})\n",
    "        man.get_text()\n",
    "        man = 1\n",
    "    except:\n",
    "        man = 0\n",
    "    try:\n",
    "        woman = i.find(name='li', attrs={'class':'icon_woman sight_out'})\n",
    "        woman.get_text()\n",
    "        woman = 1\n",
    "    except:\n",
    "        woman = 0\n",
    "    try:\n",
    "        img = i.find(name='img', attrs={'class':'lazyload lazy'})\n",
    "        img.attrs['data-original']\n",
    "        tmp_url = img.attrs['data-original']\n",
    "        if man == 1:\n",
    "            try:\n",
    "                with urlopen(tmp_url) as f:\n",
    "                    with open(my_Url + '/top/man/img' + str(n) + '.jpg', 'wb') as h:\n",
    "                        img = f.read()\n",
    "                        h.write(img)\n",
    "                        n+=1\n",
    "            except:\n",
    "                continue\n",
    "        if woman == 1:\n",
    "            try:\n",
    "                with urlopen(tmp_url) as f:\n",
    "                    with open(my_Url + '/top/woman/img' + str(m) + '.jpg', 'wb') as h:\n",
    "                        img = f.read()\n",
    "                        h.write(img)\n",
    "                        m+=1\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        continue\n",
    "print('done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensw",
   "language": "python",
   "name": "opensw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
